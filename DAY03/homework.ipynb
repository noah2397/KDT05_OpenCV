{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "data = ImageFolder(root = \"./image\", transform=transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((50,50))]))\n",
    "data_test = ImageFolder(root = \"./image_test\", transform=transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((50,50))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes, data.class_to_idx, len(data.imgs)\n",
    "test=data.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    118\n",
       "1     78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.Series(np.array(test)[:,1].astype(\"uint8\")).value_counts()\n",
    "# 대략 1.5:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler \n",
    "import numpy as np \n",
    "import torch\n",
    "\n",
    "num_data = 118\n",
    "min_weight = 0.001\n",
    "max_weight = 10000  \n",
    "\n",
    "log_weights = np.linspace(np.log(min_weight), np.log(max_weight), num_data)\n",
    "weights = np.exp(log_weights)\n",
    "\n",
    "num_data = 78\n",
    "min_weight = 0.001\n",
    "max_weight = 10000  \n",
    "\n",
    "log_weights = np.linspace(np.log(min_weight), np.log(max_weight), num_data)\n",
    "weights2 = np.exp(log_weights)\n",
    "\n",
    "#================================================================================================\n",
    "# \n",
    "weights = [1/118 for _ in range(118)]\n",
    "weights2 = [1/78 for _ in range(78)]\n",
    "\n",
    "\n",
    "weights=np.hstack((weights,weights2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(torch.DoubleTensor(list(weights)), 118+78, replacement=False)\n",
    "data_loader = DataLoader(data, batch_size=8, sampler=sampler)\n",
    "data_loader2 = DataLoader(data_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathn\\.conda\\envs\\Torch_PY38\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 50, 50]) tensor([0, 0, 1, 1, 1, 0, 1, 1])\n",
      "torch.Size([8, 3, 50, 50]) tensor([1, 0, 1, 0, 1, 1, 1, 1])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 1, 1, 0, 0, 0, 0, 1])\n",
      "torch.Size([8, 3, 50, 50]) tensor([1, 0, 0, 1, 1, 0, 1, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 0, 1, 0, 0, 0, 0, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 1, 1, 1, 0, 0, 0, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 1, 0, 1, 1, 0, 1, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([1, 0, 0, 0, 1, 0, 0, 1])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 1, 0, 0, 0, 0, 0, 1])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 1, 0, 1, 1, 0, 0, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 1, 1, 0, 1, 1, 0, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 1, 0, 0, 1, 1, 1, 1])\n",
      "torch.Size([8, 3, 50, 50]) tensor([1, 1, 1, 0, 1, 0, 0, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([1, 1, 0, 0, 1, 0, 0, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 0, 0, 1, 0, 0, 0, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 1, 0, 0, 1, 1, 0, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([1, 0, 1, 1, 0, 0, 0, 1])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 0, 1, 0, 1, 0, 0, 1])\n",
      "torch.Size([8, 3, 50, 50]) tensor([1, 0, 1, 0, 1, 0, 1, 1])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 0, 0, 1, 0, 0, 1, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 0, 1, 0, 0, 0, 0, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([8, 3, 50, 50]) tensor([1, 1, 1, 0, 1, 0, 0, 1])\n",
      "torch.Size([8, 3, 50, 50]) tensor([1, 0, 1, 0, 0, 0, 1, 0])\n",
      "torch.Size([4, 3, 50, 50]) tensor([0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for i,j in data_loader:\n",
    "    print(i.shape, j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 클래스 생성\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 9 * 9, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 9 * 9)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 생성, Adam 옵티마이저 생성\n",
    "import torch.optim as optim\n",
    "\n",
    "model = CNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(0.7000)\n",
      "정확도 :  tensor(0.)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(0.7000)\n",
      "정확도 :  tensor(0.)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(0.9000)\n",
      "정확도 :  tensor(0.4444)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(0.5556)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(0.9000)\n",
      "정확도 :  tensor(0.4444)\n",
      "정확도 :  tensor(0.8000)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(0.7778)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(0.8000)\n",
      "정확도 :  tensor(0.2222)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(0.7778)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(1.)\n",
      "정확도 :  tensor(0.8889)\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics.functional as metrics\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(data_loader):\n",
    "        x, y = data\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            pass\n",
    "            #print(epoch, i, loss.item())\n",
    "    \n",
    "    with torch.no_grad() : \n",
    "        for i, data in enumerate(data_loader2):\n",
    "            x, y = data\n",
    "            output = model(x)\n",
    "            print(\"정확도 : \",metrics.accuracy(output.argmax(dim=1), y, task=\"binary\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "def anya_bekki_classification(filepath):\n",
    "    img=cv2.imread(filepath)\n",
    "\n",
    "    # 해당 이미지를 50,50으로 만들기\n",
    "    img = cv2.resize(img, (50,50))\n",
    "    cv2.imshow(\"img\", img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if not model(torch.FloatTensor(img.reshape(1,3,50,50))).argmax() :\n",
    "        print(\"아냐~\")\n",
    "    else : \n",
    "        print(\"베키.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "베키.\n"
     ]
    }
   ],
   "source": [
    "filepath=\"./image_test/bekki/B.jpg\"\n",
    "anya_bekki_classification(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아냐~\n"
     ]
    }
   ],
   "source": [
    "filepath=\"./image_test/anya/test1.png\"\n",
    "anya_bekki_classification(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
