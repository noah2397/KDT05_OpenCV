{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PNG', 401, 321, 'RGBA', PIL.PngImagePlugin.PngImageFile)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img= Image.open(fp='../textbook.png')\n",
    "img.format, img.height, img.width, img.mode, type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 401, 321]) 3 tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "catTS=to_tensor(img)\n",
    "print(catTS.shape, catTS.ndim, catTS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (401, 321, 3) 3\n",
      "<class 'numpy.ndarray'> (401, 321, 3) 3\n",
      "torch.Size([3, 401, 321]) 3 tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "torch.Size([3, 401, 321]) 3 tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img=cv2.imread(\"../textbook.png\")\n",
    "\n",
    "\n",
    "img2=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(type(img), img.shape, img.ndim)\n",
    "print(type(img2), img2.shape, img2.ndim)\n",
    "\n",
    "cat2=to_tensor(img)\n",
    "cat3=to_tensor(img2)\n",
    "\n",
    "print(cat2.shape, cat2.ndim, cat2[0])\n",
    "print(cat3.shape, cat3.ndim, cat3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize=transforms.Resize((50,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing=transforms.Compose(\n",
    "    [transforms.Resize((50,50)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data = ImageFolder(root = \"../data/image\", transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['folder1', 'folder2'],\n",
       " {'folder1': 0, 'folder2': 1},\n",
       " [('../data/image\\\\folder1\\\\textbook copy 10.png', 0),\n",
       "  ('../data/image\\\\folder1\\\\textbook copy 8.png', 0),\n",
       "  ('../data/image\\\\folder1\\\\textbook copy 9.png', 0),\n",
       "  ('../data/image\\\\folder1\\\\textbook copy.png', 0),\n",
       "  ('../data/image\\\\folder1\\\\textbook.png', 0),\n",
       "  ('../data/image\\\\folder2\\\\textbook copy 2.png', 1),\n",
       "  ('../data/image\\\\folder2\\\\textbook copy 3.png', 1),\n",
       "  ('../data/image\\\\folder2\\\\textbook copy 4.png', 1),\n",
       "  ('../data/image\\\\folder2\\\\textbook copy 5.png', 1),\n",
       "  ('../data/image\\\\folder2\\\\textbook copy 6.png', 1),\n",
       "  ('../data/image\\\\folder2\\\\textbook copy 7.png', 1)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.classes, data.class_to_idx, data.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 401, 321]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(data_loader))\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
