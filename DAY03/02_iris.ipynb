{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as npy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv(\"iris.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.iloc[:,0:4]\n",
    "target = df.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le=LabelEncoder()\n",
    "target = pd.Series(le.fit_transform(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    40\n",
       "2    40\n",
       "0    40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 생성\n",
    "class IrisDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features.iloc[idx].values, dtype=torch.float32), torch.tensor(self.target.iloc[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train = pd.concat([X_train, y_train], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train.sort_index(inplace=True)\n",
    "X_train=combined_train.iloc[:,0:4]\n",
    "y_train=combined_train.iloc[:,4]\n",
    "\n",
    "combined_test = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test.sort_index(inplace=True)\n",
    "X_test=combined_test.iloc[:,0:4]\n",
    "y_test=combined_test.iloc[:,4]\n",
    "\n",
    "trainData = IrisDataset(X_train, y_train)\n",
    "testData = IrisDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      0\n",
       "12     0\n",
       "14     0\n",
       "18     0\n",
       "20     0\n",
       "22     0\n",
       "27     0\n",
       "31     0\n",
       "34     0\n",
       "48     0\n",
       "50     1\n",
       "54     1\n",
       "60     1\n",
       "62     1\n",
       "71     1\n",
       "72     1\n",
       "73     1\n",
       "77     1\n",
       "86     1\n",
       "87     1\n",
       "100    2\n",
       "108    2\n",
       "109    2\n",
       "111    2\n",
       "112    2\n",
       "120    2\n",
       "122    2\n",
       "130    2\n",
       "135    2\n",
       "145    2\n",
       "Name: 0, dtype: int32"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 생성\n",
    "trainLoader = torch.utils.data.DataLoader(trainData, batch_size=10, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(testData, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch_data(loader, epochs, batch_size=1, shuffle=False, drop_last=False, sampler=None):\n",
    "    print(f'[설정값] batch size : {batch_size}, shuffle : {shuffle}, drop_last : {drop_last}, sampler : {sampler}')\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        print(f'[{ep} EPOCHS]=====batch : {len(loader)}개')\n",
    "        for feature, label in loader:\n",
    "            print(feature.shape,label.shape, label.bincount(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[설정값] batch size : 1, shuffle : False, drop_last : False, sampler : None\n",
      "[0 EPOCHS]=====batch : 3개\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([10]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([ 0, 10]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([ 0,  0, 10]) tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "[1 EPOCHS]=====batch : 3개\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([10]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([ 0, 10]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([ 0,  0, 10]) tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print_batch_data(loader=testLoader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([5.1000, 3.5000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([4.9000, 3.0000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([4.7000, 3.2000, 1.3000, 0.2000]), tensor(0))\n",
      "(tensor([4.6000, 3.1000, 1.5000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.6000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([4.6000, 3.4000, 1.4000, 0.3000]), tensor(0))\n",
      "(tensor([5.0000, 3.4000, 1.5000, 0.2000]), tensor(0))\n",
      "(tensor([4.4000, 2.9000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([4.9000, 3.1000, 1.5000, 0.1000]), tensor(0))\n",
      "(tensor([5.4000, 3.7000, 1.5000, 0.2000]), tensor(0))\n",
      "(tensor([4.8000, 3.4000, 1.6000, 0.2000]), tensor(0))\n",
      "(tensor([4.3000, 3.0000, 1.1000, 0.1000]), tensor(0))\n",
      "(tensor([5.7000, 4.4000, 1.5000, 0.4000]), tensor(0))\n",
      "(tensor([5.4000, 3.9000, 1.3000, 0.4000]), tensor(0))\n",
      "(tensor([5.1000, 3.5000, 1.4000, 0.3000]), tensor(0))\n",
      "(tensor([5.1000, 3.8000, 1.5000, 0.3000]), tensor(0))\n",
      "(tensor([5.1000, 3.7000, 1.5000, 0.4000]), tensor(0))\n",
      "(tensor([5.1000, 3.3000, 1.7000, 0.5000]), tensor(0))\n",
      "(tensor([4.8000, 3.4000, 1.9000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.0000, 1.6000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.4000, 1.6000, 0.4000]), tensor(0))\n",
      "(tensor([5.2000, 3.4000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([4.7000, 3.2000, 1.6000, 0.2000]), tensor(0))\n",
      "(tensor([4.8000, 3.1000, 1.6000, 0.2000]), tensor(0))\n",
      "(tensor([5.2000, 4.1000, 1.5000, 0.1000]), tensor(0))\n",
      "(tensor([5.5000, 4.2000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.2000, 1.2000, 0.2000]), tensor(0))\n",
      "(tensor([5.5000, 3.5000, 1.3000, 0.2000]), tensor(0))\n",
      "(tensor([4.9000, 3.1000, 1.5000, 0.1000]), tensor(0))\n",
      "(tensor([4.4000, 3.0000, 1.3000, 0.2000]), tensor(0))\n",
      "(tensor([5.1000, 3.4000, 1.5000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.5000, 1.3000, 0.3000]), tensor(0))\n",
      "(tensor([4.5000, 2.3000, 1.3000, 0.3000]), tensor(0))\n",
      "(tensor([4.4000, 3.2000, 1.3000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.5000, 1.6000, 0.6000]), tensor(0))\n",
      "(tensor([5.1000, 3.8000, 1.9000, 0.4000]), tensor(0))\n",
      "(tensor([4.8000, 3.0000, 1.4000, 0.3000]), tensor(0))\n",
      "(tensor([5.1000, 3.8000, 1.6000, 0.2000]), tensor(0))\n",
      "(tensor([4.6000, 3.2000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([5.0000, 3.3000, 1.4000, 0.2000]), tensor(0))\n",
      "(tensor([6.4000, 3.2000, 4.5000, 1.5000]), tensor(1))\n",
      "(tensor([6.9000, 3.1000, 4.9000, 1.5000]), tensor(1))\n",
      "(tensor([5.5000, 2.3000, 4.0000, 1.3000]), tensor(1))\n",
      "(tensor([5.7000, 2.8000, 4.5000, 1.3000]), tensor(1))\n",
      "(tensor([6.3000, 3.3000, 4.7000, 1.6000]), tensor(1))\n",
      "(tensor([4.9000, 2.4000, 3.3000, 1.0000]), tensor(1))\n",
      "(tensor([6.6000, 2.9000, 4.6000, 1.3000]), tensor(1))\n",
      "(tensor([5.2000, 2.7000, 3.9000, 1.4000]), tensor(1))\n",
      "(tensor([5.9000, 3.0000, 4.2000, 1.5000]), tensor(1))\n",
      "(tensor([6.1000, 2.9000, 4.7000, 1.4000]), tensor(1))\n",
      "(tensor([5.6000, 2.9000, 3.6000, 1.3000]), tensor(1))\n",
      "(tensor([6.7000, 3.1000, 4.4000, 1.4000]), tensor(1))\n",
      "(tensor([5.6000, 3.0000, 4.5000, 1.5000]), tensor(1))\n",
      "(tensor([5.8000, 2.7000, 4.1000, 1.0000]), tensor(1))\n",
      "(tensor([6.2000, 2.2000, 4.5000, 1.5000]), tensor(1))\n",
      "(tensor([5.6000, 2.5000, 3.9000, 1.1000]), tensor(1))\n",
      "(tensor([5.9000, 3.2000, 4.8000, 1.8000]), tensor(1))\n",
      "(tensor([6.4000, 2.9000, 4.3000, 1.3000]), tensor(1))\n",
      "(tensor([6.6000, 3.0000, 4.4000, 1.4000]), tensor(1))\n",
      "(tensor([6.8000, 2.8000, 4.8000, 1.4000]), tensor(1))\n",
      "(tensor([6.0000, 2.9000, 4.5000, 1.5000]), tensor(1))\n",
      "(tensor([5.7000, 2.6000, 3.5000, 1.0000]), tensor(1))\n",
      "(tensor([5.5000, 2.4000, 3.8000, 1.1000]), tensor(1))\n",
      "(tensor([5.5000, 2.4000, 3.7000, 1.0000]), tensor(1))\n",
      "(tensor([5.8000, 2.7000, 3.9000, 1.2000]), tensor(1))\n",
      "(tensor([6.0000, 2.7000, 5.1000, 1.6000]), tensor(1))\n",
      "(tensor([5.4000, 3.0000, 4.5000, 1.5000]), tensor(1))\n",
      "(tensor([6.0000, 3.4000, 4.5000, 1.6000]), tensor(1))\n",
      "(tensor([5.6000, 3.0000, 4.1000, 1.3000]), tensor(1))\n",
      "(tensor([5.5000, 2.5000, 4.0000, 1.3000]), tensor(1))\n",
      "(tensor([5.5000, 2.6000, 4.4000, 1.2000]), tensor(1))\n",
      "(tensor([6.1000, 3.0000, 4.6000, 1.4000]), tensor(1))\n",
      "(tensor([5.8000, 2.6000, 4.0000, 1.2000]), tensor(1))\n",
      "(tensor([5.0000, 2.3000, 3.3000, 1.0000]), tensor(1))\n",
      "(tensor([5.6000, 2.7000, 4.2000, 1.3000]), tensor(1))\n",
      "(tensor([5.7000, 3.0000, 4.2000, 1.2000]), tensor(1))\n",
      "(tensor([5.7000, 2.9000, 4.2000, 1.3000]), tensor(1))\n",
      "(tensor([6.2000, 2.9000, 4.3000, 1.3000]), tensor(1))\n",
      "(tensor([5.1000, 2.5000, 3.0000, 1.1000]), tensor(1))\n",
      "(tensor([5.7000, 2.8000, 4.1000, 1.3000]), tensor(1))\n",
      "(tensor([5.8000, 2.7000, 5.1000, 1.9000]), tensor(2))\n",
      "(tensor([7.1000, 3.0000, 5.9000, 2.1000]), tensor(2))\n",
      "(tensor([6.3000, 2.9000, 5.6000, 1.8000]), tensor(2))\n",
      "(tensor([6.5000, 3.0000, 5.8000, 2.2000]), tensor(2))\n",
      "(tensor([7.6000, 3.0000, 6.6000, 2.1000]), tensor(2))\n",
      "(tensor([4.9000, 2.5000, 4.5000, 1.7000]), tensor(2))\n",
      "(tensor([7.3000, 2.9000, 6.3000, 1.8000]), tensor(2))\n",
      "(tensor([6.5000, 3.2000, 5.1000, 2.0000]), tensor(2))\n",
      "(tensor([5.7000, 2.5000, 5.0000, 2.0000]), tensor(2))\n",
      "(tensor([5.8000, 2.8000, 5.1000, 2.4000]), tensor(2))\n",
      "(tensor([6.4000, 3.2000, 5.3000, 2.3000]), tensor(2))\n",
      "(tensor([6.5000, 3.0000, 5.5000, 1.8000]), tensor(2))\n",
      "(tensor([7.7000, 3.8000, 6.7000, 2.2000]), tensor(2))\n",
      "(tensor([7.7000, 2.6000, 6.9000, 2.3000]), tensor(2))\n",
      "(tensor([6.0000, 2.2000, 5.0000, 1.5000]), tensor(2))\n",
      "(tensor([5.6000, 2.8000, 4.9000, 2.0000]), tensor(2))\n",
      "(tensor([6.3000, 2.7000, 4.9000, 1.8000]), tensor(2))\n",
      "(tensor([6.7000, 3.3000, 5.7000, 2.1000]), tensor(2))\n",
      "(tensor([7.2000, 3.2000, 6.0000, 1.8000]), tensor(2))\n",
      "(tensor([6.2000, 2.8000, 4.8000, 1.8000]), tensor(2))\n",
      "(tensor([6.1000, 3.0000, 4.9000, 1.8000]), tensor(2))\n",
      "(tensor([6.4000, 2.8000, 5.6000, 2.1000]), tensor(2))\n",
      "(tensor([7.2000, 3.0000, 5.8000, 1.6000]), tensor(2))\n",
      "(tensor([7.9000, 3.8000, 6.4000, 2.0000]), tensor(2))\n",
      "(tensor([6.4000, 2.8000, 5.6000, 2.2000]), tensor(2))\n",
      "(tensor([6.3000, 2.8000, 5.1000, 1.5000]), tensor(2))\n",
      "(tensor([6.1000, 2.6000, 5.6000, 1.4000]), tensor(2))\n",
      "(tensor([6.3000, 3.4000, 5.6000, 2.4000]), tensor(2))\n",
      "(tensor([6.4000, 3.1000, 5.5000, 1.8000]), tensor(2))\n",
      "(tensor([6.0000, 3.0000, 4.8000, 1.8000]), tensor(2))\n",
      "(tensor([6.9000, 3.1000, 5.4000, 2.1000]), tensor(2))\n",
      "(tensor([6.7000, 3.1000, 5.6000, 2.4000]), tensor(2))\n",
      "(tensor([6.9000, 3.1000, 5.1000, 2.3000]), tensor(2))\n",
      "(tensor([5.8000, 2.7000, 5.1000, 1.9000]), tensor(2))\n",
      "(tensor([6.8000, 3.2000, 5.9000, 2.3000]), tensor(2))\n",
      "(tensor([6.7000, 3.3000, 5.7000, 2.5000]), tensor(2))\n",
      "(tensor([6.3000, 2.5000, 5.0000, 1.9000]), tensor(2))\n",
      "(tensor([6.5000, 3.0000, 5.2000, 2.0000]), tensor(2))\n",
      "(tensor([6.2000, 3.4000, 5.4000, 2.3000]), tensor(2))\n",
      "(tensor([5.9000, 3.0000, 5.1000, 1.8000]), tensor(2))\n"
     ]
    }
   ],
   "source": [
    "for i in trainData:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[설정값] batch size : 1, shuffle : False, drop_last : False, sampler : None\n",
      "[0 EPOCHS]=====batch : 12개\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([3, 4, 3]) tensor([0, 0, 0, 2, 1, 1, 2, 1, 1, 2])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([2, 4, 4]) tensor([1, 0, 1, 2, 0, 2, 2, 1, 1, 2])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([4, 2, 4]) tensor([2, 0, 2, 0, 2, 0, 2, 1, 0, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([3, 3, 4]) tensor([0, 1, 2, 0, 2, 2, 2, 0, 1, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([5, 2, 3]) tensor([0, 0, 0, 0, 2, 2, 0, 1, 2, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([3, 5, 2]) tensor([1, 2, 1, 0, 0, 1, 1, 2, 0, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([5, 3, 2]) tensor([1, 0, 0, 0, 0, 2, 2, 1, 0, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([2, 5, 3]) tensor([0, 2, 1, 2, 1, 1, 1, 1, 0, 2])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([2, 4, 4]) tensor([2, 1, 1, 2, 2, 1, 0, 2, 1, 0])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([5, 1, 4]) tensor([0, 2, 2, 0, 0, 0, 1, 2, 2, 0])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([2, 4, 4]) tensor([2, 2, 1, 0, 1, 1, 2, 0, 1, 2])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([4, 3, 3]) tensor([1, 2, 0, 0, 2, 1, 0, 1, 2, 0])\n",
      "[1 EPOCHS]=====batch : 12개\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([2, 4, 4]) tensor([1, 1, 1, 2, 0, 2, 1, 2, 0, 2])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([5, 2, 3]) tensor([0, 0, 0, 2, 0, 2, 1, 1, 0, 2])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([2, 5, 3]) tensor([1, 1, 2, 0, 1, 2, 1, 0, 2, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([4, 3, 3]) tensor([0, 1, 1, 0, 2, 0, 2, 0, 1, 2])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([4, 3, 3]) tensor([0, 1, 2, 0, 2, 0, 1, 2, 0, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([3, 5, 2]) tensor([1, 0, 1, 0, 1, 1, 0, 2, 2, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([2, 3, 5]) tensor([0, 1, 1, 2, 2, 2, 0, 2, 2, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([6, 1, 3]) tensor([0, 0, 2, 1, 0, 0, 2, 2, 0, 0])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([3, 2, 5]) tensor([2, 0, 2, 1, 2, 1, 0, 0, 2, 2])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([4, 3, 3]) tensor([0, 2, 1, 2, 0, 0, 0, 1, 1, 2])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([1, 6, 3]) tensor([1, 2, 1, 1, 2, 1, 0, 2, 1, 1])\n",
      "torch.Size([10, 4]) torch.Size([10]) tensor([4, 3, 3]) tensor([0, 1, 1, 1, 0, 0, 2, 2, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "num_data = 40\n",
    "min_weight = 0.001\n",
    "max_weight = 10000  \n",
    "\n",
    "log_weights = np.linspace(np.log(min_weight), np.log(max_weight), num_data)\n",
    "weights = np.exp(log_weights)\n",
    "\n",
    "\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(list(weights)*3), num_data*3, replacement=False)\n",
    "trainLoader = DataLoader(trainData, batch_size=10, sampler=sampler)\n",
    "\n",
    "\n",
    "print_batch_data(loader=trainLoader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(weights)*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "\n",
    "# 가상의 데이터셋 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.targets[index]\n",
    "\n",
    "# 가상의 데이터셋 생성\n",
    "data = [...]  # 데이터\n",
    "targets = [...]  # 라벨\n",
    "\n",
    "# 클래스별 샘플 수 계산\n",
    "class_counts = torch.bincount(torch.tensor(targets))\n",
    "\n",
    "# 클래스별 가중치 계산\n",
    "class_weights = 1. / class_counts.float()\n",
    "\n",
    "# 샘플링 가중치 생성\n",
    "example_weights = class_weights[targets]\n",
    "\n",
    "# WeightedRandomSampler를 사용하여 데이터로더 생성\n",
    "sampler = WeightedRandomSampler(weights=example_weights, num_samples=len(example_weights))\n",
    "\n",
    "# 데이터로더 설정\n",
    "batch_size = 32\n",
    "dataset = CustomDataset(data, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "# 모델 훈련\n",
    "for inputs, targets in dataloader:\n",
    "    # 모델 학습 코드\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
